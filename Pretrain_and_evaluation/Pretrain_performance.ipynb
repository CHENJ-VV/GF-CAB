{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_from_disk, Dataset\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import os\n",
    "import sys\n",
    "import pytz\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "\n",
    "from transformers import BertConfig, BertForMaskedLM, TrainingArguments, TrainerCallback, Trainer, BertModel, BertPreTrainedModel\n",
    "from transformers.modeling_outputs import MaskedLMOutput\n",
    "from transformers.models.bert.modeling_bert import BertLMPredictionHead, BertOnlyMLMHead, BertPredictionHeadTransform\n",
    "from transformers.activations import ACT2FN\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import torch.nn.functional as F\n",
    "from geneformer.pretrainer import token_dictionary\n",
    "from geneformer import GeneformerPretrainer\n",
    "\n",
    "'''Import Customized Model Structures'''\n",
    "from GF_CAB import CustomBertForMaskedLM\n",
    "\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "os.environ[\"OMPI_MCA_opal_cuda_support\"] = \"true\"\n",
    "os.environ[\"CONDA_OVERRIDE_GLIBC\"] = \"2.56\"\n",
    "\n",
    "seed_num = 42\n",
    "random.seed(seed_num)\n",
    "np.random.seed(seed_num)\n",
    "seed_val = 42\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# set local time/directories\n",
    "timezone = pytz.timezone(\"Asia/Riyadh\")\n",
    "rootdir = os.getcwd() + \"/Self_train\"\n",
    "\n",
    "\n",
    "corpus_dir = \"Pretrain_data\"\n",
    "with open(corpus_dir + \"/token_dictionary.pkl\", \"rb\") as fp:\n",
    "    token_dictionary = pickle.load(fp)\n",
    "\n",
    "len_vocabulary = len(token_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model parameters\n",
    "# model type\n",
    "model_type = \"bert\"\n",
    "# max input size\n",
    "max_input_size = 2**11  # 2048\n",
    "# number of layers\n",
    "num_layers = 6\n",
    "# number of attention heads\n",
    "num_attn_heads = 4\n",
    "# number of embedding dimensions\n",
    "num_embed_dim = 256\n",
    "# intermediate size\n",
    "intermed_size = num_embed_dim * 2\n",
    "# activation function\n",
    "activ_fn = \"relu\"\n",
    "# initializer range, layer norm, dropout\n",
    "initializer_range = 0.02\n",
    "layer_norm_eps = 1e-12\n",
    "attention_probs_dropout_prob = 0.02\n",
    "hidden_dropout_prob = 0.02\n",
    "\n",
    "# set training parameters\n",
    "# total number of examples in Genecorpus-30M after QC filtering:\n",
    "num_examples = 27_406_208\n",
    "subset = 1_000_000\n",
    "# number gpus\n",
    "num_gpus = 8\n",
    "# batch size for training and eval\n",
    "geneformer_batch_size = 10\n",
    "# max learning rate\n",
    "max_lr = 1e-3\n",
    "# learning schedule\n",
    "lr_schedule_fn = \"linear\"\n",
    "# warmup steps\n",
    "warmup_steps = 10_000\n",
    "# number of epochs\n",
    "epochs = 3\n",
    "# optimizer\n",
    "optimizer = \"adamw\"\n",
    "# weight_decay\n",
    "weight_decay = 0.001\n",
    "\n",
    "\n",
    "# output directories\n",
    "current_date = datetime.datetime.now(tz=timezone)\n",
    "datestamp = f\"{str(current_date.year)[-2:]}{current_date.month:02d}{current_date.day:02d}_{current_date.strftime('%X').replace(':','')}\"\n",
    "run_name = f\"{datestamp}_geneformer_30M_L{num_layers}_emb{num_embed_dim}_SL{max_input_size}_E{epochs}_B{geneformer_batch_size}_LR{max_lr}_LS{lr_schedule_fn}_WU{warmup_steps}_O{optimizer}_DS{num_gpus}\"\n",
    "training_output_dir = f\"{rootdir}/models/{run_name}/\"\n",
    "logging_dir = f\"{rootdir}/runs/{run_name}/\"\n",
    "model_output_dir = os.path.join(training_output_dir, \"models/\")\n",
    "\n",
    "\n",
    "model_output_file = os.path.join(model_output_dir, \"pytorch_model.bin\")\n",
    "if os.path.isfile(model_output_file) is True:\n",
    "    raise Exception(\"Model already saved to this directory.\")\n",
    "\n",
    "# make training and model output directories\n",
    "os.makedirs(training_output_dir, exist_ok=True)\n",
    "os.makedirs(model_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = 'model path'\n",
    "cosine_val = str(5)\n",
    "scale_val  = str(1)\n",
    "model = CustomBertForMaskedLM.from_pretrained(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids'],\n",
      "    num_rows: 50000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "path_to_dataset = \"Pretrain_data/subset_5M_genecorpus.dataset\"\n",
    "path_to_dataset = os.path.expanduser(path_to_dataset)\n",
    "\n",
    "# Load the dataset from disk\n",
    "genecorpus = load_from_disk(path_to_dataset)\n",
    "\n",
    "sample_size = 50_000\n",
    "\n",
    "test_dataset = genecorpus.shuffle(seed=666).select(list(range(sample_size)))\n",
    "print(test_dataset)\n",
    "\n",
    "batch_size = 100\n",
    "batch_num = sample_size // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    \"learning_rate\": max_lr,\n",
    "    \"do_train\": False,\n",
    "    \"do_eval\": False,\n",
    "    \"group_by_length\": True,\n",
    "    \"length_column_name\": \"length\",\n",
    "    \"disable_tqdm\": False,\n",
    "    \"lr_scheduler_type\": lr_schedule_fn,\n",
    "    \"warmup_steps\": warmup_steps,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"per_device_train_batch_size\": geneformer_batch_size,\n",
    "    \"num_train_epochs\": epochs,\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": np.floor(subset / geneformer_batch_size / 8),  # 8 saves per epoch\n",
    "    \"logging_steps\": 1000,\n",
    "    \"output_dir\": training_output_dir,\n",
    "    \"logging_dir\": logging_dir,\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(**training_args)\n",
    "\n",
    "# define the trainer\n",
    "trainer = GeneformerPretrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=None,\n",
    "    example_lengths_file=\"Pretrain_data/sub_5M_genecorpus_30M_2048_lengths.pkl\",\n",
    "    token_dictionary=token_dictionary,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Avoid memory blow-up ---\n",
    "all_labels_pre = []\n",
    "all_labels_gt = []\n",
    "\n",
    "for i in tqdm(range(batch_num), colour=\"purple\", desc=\"Batch Prediction\"):\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + batch_size\n",
    "    mini_batch = test_dataset.select(range(start_index, end_index))\n",
    "\n",
    "    # Predict without keeping trainer caches\n",
    "    mini_predictions = trainer.predict(mini_batch)\n",
    "\n",
    "    predictions_batch = np.argmax(mini_predictions.predictions, axis=-1).astype(\"int32\")\n",
    "    all_labels_gt.append(mini_predictions.label_ids)\n",
    "    all_labels_pre.append(predictions_batch)\n",
    "    # Free memory\n",
    "    del mini_predictions\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building final concatenated arrays...\n",
      "Max sequence length: 2048\n",
      "Total samples: 50000\n",
      "Number of batches: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c35248d40af4dd1886768370bc432c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29eb343d7e6e4d0ba98619c2377da3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing input_ids:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final array shapes:\n",
      "input_ids: (50000, 2048)\n",
      "labels_pre: (50000, 2048)\n",
      "all_labels_gt: (50000, 2048)\n"
     ]
    }
   ],
   "source": [
    "def build_final_arrays(all_labels_pre, all_labels_gt, test_dataset):\n",
    "    \"\"\"\n",
    "    Build final concatenated arrays for input_ids, labels_pre, and all_labels_gt\n",
    "    Works directly on precomputed predictions (no logits kept).\n",
    "    \"\"\"\n",
    "    print('Building final concatenated arrays...')\n",
    "    \n",
    "    max_dim2 = max(arr.shape[1] for arr in all_labels_pre)\n",
    "    total_samples = sum(arr.shape[0] for arr in all_labels_pre)\n",
    "    \n",
    "    print(f'Max sequence length: {max_dim2}')\n",
    "    print(f'Total samples: {total_samples}')\n",
    "    print(f'Number of batches: {len(all_labels_pre)}')\n",
    "    \n",
    "    # Pre-allocate\n",
    "    labels_pre_final = np.full((total_samples, max_dim2), -100, dtype=np.int32)\n",
    "    all_labels_gt_final = np.full((total_samples, max_dim2), -100, dtype=all_labels_gt[0].dtype)\n",
    "    \n",
    "    # Fill arrays\n",
    "    current_idx = 0\n",
    "    for batch_idx in tqdm(range(len(all_labels_pre)), desc=\"Processing batches\"):\n",
    "        preds = all_labels_pre[batch_idx]\n",
    "        labels = all_labels_gt[batch_idx]\n",
    "        \n",
    "        batch_size, seq_len = preds.shape\n",
    "        labels_pre_final[current_idx:current_idx+batch_size, :seq_len] = preds\n",
    "        all_labels_gt_final[current_idx:current_idx+batch_size, :seq_len] = labels\n",
    "        current_idx += batch_size\n",
    "        \n",
    "        del preds, labels\n",
    "        gc.collect()\n",
    "    \n",
    "    # Process input_ids\n",
    "    input_ids_list = [np.array(seq) for seq in test_dataset[\"input_ids\"]]\n",
    "    max_input_dim = max(arr.shape[0] for arr in input_ids_list)\n",
    "    input_ids_final = np.zeros((len(input_ids_list), max_input_dim), dtype=np.int32)\n",
    "    for i, arr in enumerate(tqdm(input_ids_list, desc=\"Processing input_ids\")):\n",
    "        input_ids_final[i, :arr.shape[0]] = arr\n",
    "    \n",
    "    del input_ids_list\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"\\nFinal array shapes:\")\n",
    "    print(f\"input_ids: {input_ids_final.shape}\")\n",
    "    print(f\"labels_pre: {labels_pre_final.shape}\")\n",
    "    print(f\"all_labels_gt: {all_labels_gt_final.shape}\")\n",
    "    \n",
    "    return input_ids_final, labels_pre_final, all_labels_gt_final\n",
    "\n",
    "\n",
    "input_ids, labels_pre, all_labels_gt = build_final_arrays(all_labels_pre, all_labels_gt, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing repeat ratios (vectorized)...\n",
      "\n",
      "Repeat ratio stats:\n",
      "Unmasked overlap mean: 4.49%\n",
      "Masked repetition mean: 6.09%\n",
      "Overall repetition mean: 10.58%\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Vectorized repeat ratio computation\n",
    "# ------------------------------------------\n",
    "def compute_repeat_ratios(input_ids, labels_pre, all_labels_gt, return_gene_lists=False):\n",
    "    \"\"\"\n",
    "    Compute repeat ratios with vectorized operations.\n",
    "    Optionally also return lists of repeating genes and counts (slower).\n",
    "    \"\"\"\n",
    "\n",
    "    num_samples, seq_len = labels_pre.shape\n",
    "    vocab_size = input_ids.max() + 1  # assume contiguous ids\n",
    "\n",
    "    # Masks\n",
    "    mask = all_labels_gt != -100       # masked positions\n",
    "    unmask = all_labels_gt == -100     # unmasked positions\n",
    "\n",
    "    # Predictions only at masked positions\n",
    "    seq_pre = np.where(mask, labels_pre, -100)\n",
    "    seq_unmask = np.where(unmask, input_ids, -100)\n",
    "\n",
    "    # Number of predictions per sequence\n",
    "    masked_counts = mask.sum(axis=1)\n",
    "\n",
    "    # --- Count predictions per sequence (dense [num_samples, vocab_size]) ---\n",
    "    pred_counts = np.zeros((num_samples, vocab_size), dtype=np.int32)\n",
    "    for i in range(num_samples):\n",
    "        vals, counts = np.unique(seq_pre[i][seq_pre[i] != -100], return_counts=True)\n",
    "        pred_counts[i, vals] = counts\n",
    "\n",
    "    # --- Presence of unmasked genes ---\n",
    "    unmask_presence = np.zeros((num_samples, vocab_size), dtype=bool)\n",
    "    for i in range(num_samples):\n",
    "        vals = np.unique(seq_unmask[i][seq_unmask[i] != -100])\n",
    "        unmask_presence[i, vals] = True\n",
    "\n",
    "    # --- Compute repeats ---\n",
    "    # Repeats with unmasked\n",
    "    repeat_with_unmasked_count = (pred_counts * unmask_presence).sum(axis=1)\n",
    "\n",
    "    # Repeats within masked (counts > 1, subtract 1 per gene)\n",
    "    repeat_within_masked_count = np.where(pred_counts > 1, pred_counts - 1, 0).sum(axis=1)\n",
    "\n",
    "    # Total\n",
    "    total_repeat_count = repeat_with_unmasked_count + repeat_within_masked_count\n",
    "\n",
    "    # --- Ratios ---\n",
    "    repeat_ratio_unmasked = np.divide(\n",
    "        repeat_with_unmasked_count, masked_counts, out=np.zeros_like(repeat_with_unmasked_count, dtype=float), where=masked_counts > 0\n",
    "    ) * 100\n",
    "\n",
    "    repeat_ratio_masked = np.divide(\n",
    "        repeat_within_masked_count, masked_counts, out=np.zeros_like(repeat_within_masked_count, dtype=float), where=masked_counts > 0\n",
    "    ) * 100\n",
    "\n",
    "    repeat_ratio_overall = np.divide(\n",
    "        total_repeat_count, masked_counts, out=np.zeros_like(total_repeat_count, dtype=float), where=masked_counts > 0\n",
    "    ) * 100\n",
    "\n",
    "    if not return_gene_lists:\n",
    "        return repeat_ratio_unmasked, repeat_ratio_masked, repeat_ratio_overall\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Slower part: actual repeating genes & counts\n",
    "    # (requires Python loop because of variable lengths)\n",
    "    # ------------------------------------------\n",
    "    repeating_gene_list = []\n",
    "    repeating_count_list = []\n",
    "\n",
    "    for i in tqdm(range(num_samples), desc=\"Collecting gene lists\"):\n",
    "        vals, counts = np.nonzero(pred_counts[i])[0], pred_counts[i][pred_counts[i] > 0]\n",
    "\n",
    "        # Genes repeated with unmasked\n",
    "        genes_repeat_with_unmasked = vals[unmask_presence[i, vals]]\n",
    "        repeat_with_unmasked_count = counts[unmask_presence[i, vals]]\n",
    "\n",
    "        # Genes repeated within masked\n",
    "        mask_repeats = (counts > 1) & (~unmask_presence[i, vals])\n",
    "        genes_repeat_within_masked = vals[mask_repeats]\n",
    "        repeat_within_masked_count = counts[mask_repeats] - 1\n",
    "\n",
    "        # Concatenate\n",
    "        seq_total_repeated_gene = np.concatenate((genes_repeat_with_unmasked, genes_repeat_within_masked), axis=0)\n",
    "        seq_total_repeated_count = np.concatenate((repeat_with_unmasked_count, repeat_within_masked_count), axis=0)\n",
    "\n",
    "        repeating_gene_list.append(seq_total_repeated_gene)\n",
    "        repeating_count_list.append(seq_total_repeated_count)\n",
    "\n",
    "    return (repeat_ratio_unmasked, repeat_ratio_masked, repeat_ratio_overall,\n",
    "            repeating_gene_list, repeating_count_list)\n",
    "\n",
    "\n",
    "# ------------------------------------------\n",
    "# Example usage\n",
    "# ------------------------------------------\n",
    "# Suppose you already have numpy arrays:\n",
    "# input_ids, labels_pre, all_labels_gt\n",
    "# all with shape [num_samples, seq_len]\n",
    "\n",
    "print(\"Computing repeat ratios (vectorized)...\")\n",
    "repeat_ratio_unmasked, repeat_ratio_masked, repeat_ratio_overall = compute_repeat_ratios(\n",
    "    input_ids, labels_pre, all_labels_gt, return_gene_lists=False\n",
    ")\n",
    "\n",
    "print(\"\\nRepeat ratio stats:\")\n",
    "print(f\"Unmasked overlap mean: {repeat_ratio_unmasked.mean():.2f}%\")\n",
    "print(f\"Masked repetition mean: {repeat_ratio_masked.mean():.2f}%\")\n",
    "print(f\"Overall repetition mean: {repeat_ratio_overall.mean():.2f}%\")\n",
    "\n",
    "# If you also want the actual gene lists per sequence:\n",
    "# repeat_ratio_unmasked, repeat_ratio_masked, repeat_ratio_overall, \\\n",
    "#     repeating_gene_list, repeating_count_list = compute_repeat_ratios(\n",
    "#         input_ids, labels_pre, all_labels_gt, return_gene_lists=True\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0496bfaa415f42418ca8d837eff8a55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uniqueness_list = []\n",
    "for idx in tqdm(range(len(labels_pre))):\n",
    "    masked_indices = (all_labels_gt[idx] != -100).nonzero()\n",
    "    if len(masked_indices[0]) != 0:\n",
    "        masked_pres = labels_pre[idx][masked_indices]\n",
    "        unique_genes, counts = np.unique(masked_pres, return_counts=True)\n",
    "        unique_pre_counts = np.sum(counts == 1)\n",
    "        uniqueness = unique_pre_counts / counts.sum()\n",
    "    else:\n",
    "        uniqueness = 0\n",
    "    uniqueness_list.append(uniqueness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing per-sequence accuracy (vectorized)...\n",
      "Mean accuracy: 24.95%\n",
      "Std. accuracy: 15.26%\n"
     ]
    }
   ],
   "source": [
    "def compute_sequence_accuracy(input_ids, labels_pre, all_labels_gt):\n",
    "    \"\"\"\n",
    "    Vectorized computation of per-sequence accuracy (% correct at masked positions).\n",
    "    \"\"\"\n",
    "    # Masked positions\n",
    "    mask = all_labels_gt != -100  # True where labels are valid\n",
    "    \n",
    "    # True labels at masked positions\n",
    "    seq_mask = np.where(mask, all_labels_gt, -100)\n",
    "    \n",
    "    # Predictions at masked positions\n",
    "    seq_pre = np.where(mask, labels_pre, -100)\n",
    "    \n",
    "    # Correct predictions (boolean array)\n",
    "    correct = (seq_pre == seq_mask) & mask\n",
    "    \n",
    "    # Per-sequence counts\n",
    "    correct_counts = correct.sum(axis=1)\n",
    "    total_counts = mask.sum(axis=1)\n",
    "    \n",
    "    # Accuracy: correct / total (handle division by zero → 1.0 when no masked positions)\n",
    "    seq_acc = np.divide(\n",
    "        correct_counts, total_counts,\n",
    "        out=np.ones_like(correct_counts, dtype=float), where=total_counts > 0\n",
    "    ) * 100\n",
    "    \n",
    "    return seq_acc\n",
    "\n",
    "print(\"Computing per-sequence accuracy (vectorized)...\")\n",
    "seq_acc_list = compute_sequence_accuracy(input_ids, labels_pre, all_labels_gt)\n",
    "print(f\"Mean accuracy: {seq_acc_list.mean():.2f}%\")\n",
    "print(f\"Std. accuracy: {seq_acc_list.std():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Repeat Ratio</th>\n",
       "      <th>Repeat Mask</th>\n",
       "      <th>Repeat Unmask</th>\n",
       "      <th>Unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.568106</td>\n",
       "      <td>20.265781</td>\n",
       "      <td>7.641196</td>\n",
       "      <td>12.624585</td>\n",
       "      <td>0.860465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.666667</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>23.076923</td>\n",
       "      <td>10.256410</td>\n",
       "      <td>10.256410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>17.525773</td>\n",
       "      <td>21.649485</td>\n",
       "      <td>8.247423</td>\n",
       "      <td>13.402062</td>\n",
       "      <td>0.835052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>28.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>27.363184</td>\n",
       "      <td>13.930348</td>\n",
       "      <td>5.970149</td>\n",
       "      <td>7.960199</td>\n",
       "      <td>0.885572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Repeat Ratio  Repeat Mask  Repeat Unmask    Unique\n",
       "0      29.568106     20.265781     7.641196      12.624585  0.860465\n",
       "1      20.000000      0.000000     0.000000       0.000000  1.000000\n",
       "2      10.000000     10.000000    10.000000       0.000000  0.800000\n",
       "3      46.666667     13.333333    13.333333       0.000000  0.800000\n",
       "4      14.285714      0.000000     0.000000       0.000000  1.000000\n",
       "...          ...           ...          ...            ...       ...\n",
       "49995  23.076923     10.256410    10.256410       0.000000  0.820513\n",
       "49996  17.525773     21.649485     8.247423      13.402062  0.835052\n",
       "49997  28.571429      0.000000     0.000000       0.000000  1.000000\n",
       "49998  50.000000      0.000000     0.000000       0.000000  1.000000\n",
       "49999  27.363184     13.930348     5.970149       7.960199  0.885572\n",
       "\n",
       "[50000 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([seq_acc_list, repeat_ratio_overall, repeat_ratio_masked, repeat_ratio_unmasked, uniqueness_list], index = ['Accuracy', 'Repeat Ratio', 'Repeat Mask', 'Repeat Unmask', 'Unique']).T\n",
    "file_path = \"/ibex/user/chenj0i/Geneformer/\" + \"GF_Sim_Cosine_\" + cosine_val + \"_\" + scale_val + \"Mmodel_50K.csv\"\n",
    "df.to_csv(file_path)\n",
    "(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy         24.945316\n",
       "Repeat Ratio     10.582862\n",
       "Repeat Mask       6.091604\n",
       "Repeat Unmask     4.491259\n",
       "Unique            0.883583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
